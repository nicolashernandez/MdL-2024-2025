{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN3S8HMrRZA0nNMj3rGfOrk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolashernandez/MdL-2024-2025/blob/main/Generative-sampling-techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercice : Generative sampling techniques\n"
      ],
      "metadata": {
        "id": "ugK6EM2wQ-ua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1 : Temperature sampling\n",
        "\n",
        "La technique dite de l'échantillonage par température ($t$) permet de lisser (température haute) la distribution des probabilités sur toutes les options ou de concentrer (température basse) la distribution  sur les options les plus probables. Le paramètre $t$ s'applique avant que la distribution soit calculée."
      ],
      "metadata": {
        "id": "0cAGNqpxZLXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ci-dessous la fonction softmax qui permet de calculer la distribution donné x.\n",
        "\n",
        "$\\sigma(x_i) = \\frac{e^{x_{i}/t}}{\\sum_{j=1}^K e^{x_{j}/t}} \\ \\ \\ pour\\ i=1,2,\\dots,K$ et avec temperature $t=1$, pour le softmax par défaut\n",
        "\n",
        "**TODO** implémenter la fonction softmax à l'aide des fonction numpy exp et sum.\n",
        "\n",
        "Soit $x$ un vecteur avec des scores associés à 4 mots désignés par A, B, C et D tel que $x=[1.5, -1.8, 0.9, -3.2]$. Vous devriez retrouvez les résultats suivants :\n",
        "\n",
        "* t=1, softmax = `[0.62704177 0.02312729 0.34412782 0.00570312]`\n",
        "* t=0.5, softmax = `[7.67673394e-01 1.04431835e-03 2.31218783e-01 6.35050642e-05]`\n",
        "\n",
        "Si vous ne trouvez pas, jetez un oeil à la documention de [softmax sous scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.softmax.html)."
      ],
      "metadata": {
        "id": "r8TvYmSoSY02"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2pjsoQcQ95C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def softmax(x, t=1):\n",
        "  \"\"\"TODO\"\"\"\n",
        "    return None\n",
        "\n",
        "\n",
        "x = np.array([1.5, -1.8, 0.9, -3.2])\n",
        "print(softmax(x))\n",
        "print(softmax(x, t=0.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO** Observez la distribution suivant les températures. Quelle valeur de $t$ rend le système quasi-déterministe ?"
      ],
      "metadata": {
        "id": "sAjkr9hgeklT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "temperatures =  [5, 2, 1, 0.5, 0.1, 0.01]\n",
        "\n",
        "distribution = list()\n",
        "for t in temperatures:\n",
        "  distribution.append(softmax(x, t=t))\n",
        "\n",
        "df = pd.DataFrame(distribution, columns=['A', 'B', 'C', 'D'], index=temperatures)\n",
        "print (df)\n",
        "\n",
        "ax = df.plot.bar(stacked=True)\n",
        "ax.set_xlabel(\"Temperature\")\n",
        "ax.set_ylabel(\"Probability\")"
      ],
      "metadata": {
        "id": "UV4NCmKAekye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2 : \"Top K Sampling\"\n",
        "\n",
        "Pour cette question et la suivante vous utiliserez la démo suivante https://artefact2.github.io/llm-sampling/index.xhtml à la fois pour\n",
        "* observer les valeurs de la distribution initiale\n",
        "* vérifier que vos calculs sont corrects\n",
        "\n",
        "Cela implique de ne pas jouer tout de suite avec la démo...\n",
        "\n",
        "Sélectionner le contexte suivant \"*You will pay for what you have done,\" she hissed, her blade flashing in the moonlight. The battle that ensued _____*\""
      ],
      "metadata": {
        "id": "l4jeJVftReCm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "**TODO** Considérer la technique \"Top K\", calculer \"à la main\" les nouveaux scores de probabilités si K=3. Vérifier après coup."
      ],
      "metadata": {
        "id": "r_TLF7UIR2h5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3 : \"Top P Sampling\"\n",
        "\n",
        "Conserver le même contexte que précédemment sur l'espace démo.\n",
        "\n",
        "La technique d'échantillonage avec le Top P implique de garder les tokens les plus probables jusqu'à ce que la somme de leurs probabilités soit plus grande que P.\n",
        "\n",
        "**TODO** Considérer la technique \"Top P\", combien de mots seront considérés si P=0.8. Calculer les nouveaux scores de probabilité de ces mots."
      ],
      "metadata": {
        "id": "quZT_3FShDBI"
      }
    }
  ]
}